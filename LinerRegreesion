###선형회귀분석 (중고차판매_예측)


library(tidyverse)
getwd()

##절대 경로 
setwd()

##상대 경로
##setwd(dir='./rMLearning')
getwd()
list.files()

df <- read.csv(file='https://bit.ly/used_cars_price')

#데이터 프레임을 가져왔으면 Structure를 확인

str(object = df)

#Age: 개월수
#KM:주행거리
#FuelType: Diesel, Petrol, CNG ->범주형
#HP:마력 <= 120
#MetColor:금속컬러->범주형
#Automatic:미션-> 범주형
#CC:엔진크기  
#Doors:문의 개수>=3
#Weight:차량의 무게 >= 1200

##EDA를 먼저 해야 한다.

df<-df %>%
  filter(HP<=120 & Weight <=1200 & Doors>=3)

df<-df%>%select(-CC)

#CNG이 데이터 (샘플데이터)가 작아서 모형을 만드는 것이 좋지 않아서 제거


table(df$FuelType) # table() 빈도수를 보여줌


df<-df%>%
  filter(FuelType %in% c('Diesel','Petrol'))%>%
  mutate(FuelType = factor(x=FuelType),
         Automatic = factor(x=Automatic),
         MetColor = factor(x=MetColor))

str(object = df)

summary(object=df)

#정규분포 확인하는 법 (사피로 테스트)
shapiro.test(x=df$Price)

#분석 데이터셋 분할
# 전체 데이터 70%를 훈련용, 30%를 시험용 데이터로 분리

 n <-nrow(x=df)
print(n)

set.seed(seed=1234) #seed의 숫자는 의미가 있는 것은 아니다.

index<-sample(x=n, size=n*0.7, replace=FALSE)  # n=공의 개수 , size=뽑을 개수, replace= 복원(T)/비복원(F), index=행번호
print(x=index)

trainSet <-df%>%slice(index)
testSet <-df%>%slice(-index)

mean(x=trainSet$Price)
mean(x=testSet$Price)

# R에서 선형 회귀모형을 적합할 때 lm() 함수를 사용한다.
##formula : 목표변수와 입력변수 간 관계를 표현함
## data: 로지스틱 회귀모형에 사용될 훈련셋 할당

# 목표변수와 입력변수의 관계를 설졍하는 다양한 방식
##>lm(formula=Price~Age, data=trainSet)  입력변수를 한개 만 설정
##>lm(formula=Price~Age+KM, data=trainSet) 입력변수를 두 개 이상 설정할 때는 입력변수 사이에 '+' 기호를 추가
##>lm(formula=Price~,, data=trainSet)    trainSet에서 목표변수를 제외한 나머지 변수를 입력변수로 설정하고 싶은 경우, 온점(.)만 추가
###full모형 : 입력변수가 모두 쓰였으므로
##>lm(formula=Price~ 1, data=trainSet)  입력변수 하나도 없이 y절편만 설정하려면 숫자 1만 추가
### null모형 :입력변수가 하나오 없으므로

fit <- lm(formula = Price ~Age, data=trainSet)
summary(object=fit)

# 1) 최소 자승법으로 회귀 계수 추청 (Estimate )
# 2)회귀모형의 유의성 검정 : 모형(=p-value, f통게량=검정통게량을 따르는 아노바,유의 확률은 0이므로 귀무가설 기각 베타가 모두 0이다-->
#   유의성 검정 통과) --> 계수(t value Pr(>|t|), p벨류가 0이므로, 베타1이 0이라는 귀무가설은 기각한다. 따라서 0이 아니다.)
#   즉,'Age라는 변수가 증가할 때마다 -155.289만큼 가격이 빠진다'는 의미가 있다.
# 3) 결정계수 확인: 입력변수가 1개일 떄 Muliple R-squard 확인하고 2개 이상인 경우 Adjusted 항목 확인
#   입력변수가 1개 쓰인 R^2의 경우, 두 변수간 피어슨 상관계수의 제곱이 된다.
### 통게적으로 얼마나 유의한지를 보는 것이 데이터 마이닝에서 중요하다.

par(mfrow = c(2,2)) #plot창의 환경을 설정해줌. 원복할 경우 par(mfrow = c(1,1))로 바꿔준다.
plot(x=fit)
par(mfrow=c(1,1))

hist(x=fit$residuals)
shapiro.test(x=fit$residuals)  #p벨류가 1이면 귀무가설(정규분포한다)기각한다. 잔차가 정규분포 하지 않는다.

#install.packages("devtools")
#install.packages("car")

library(car)
ncvTest(model=fit)  #유의확률 0 귀무가설(등분산한다) 기각 등분산 과적 불만족
durbinWatsonTest(model=fit) # 귀무가설(자기상관계수는 0이다,상관관게가 없다) 기각하지 못한다. Alternative ~: 자기 상관게수가 0이 아니다 
crPlots(model=fit) #핑크색 선이 파란색 점선과 일치 해야 함. 위부분은 별도의 그래프를 만들면 좋을 정도로 그래프가 나옴
influencePlot(model=fit)  #Cook's distance중에 1이상이 있는가 확인


## 회귀 모형에 2차항 추가
fit2 <- lm(formula =Price ~ Age + I(x=Age^2), data=trainSet)
summary(object=fit2)
crPlots(model=fit2)
vif(mod = fit2)
# 두 입력변수의 분산팽창지수가 10을 초과하므로 다중공산성 문제가 발생하는 것으로 판단


## 목표변수의 추정값 생성 
real<- testSet$Price
print(x=real)

pred1 <- predict(object= fit, newdata=testSet)
print(x=pred1)  #named vector라고 한다 412행의 값이 7508.588

#모형성능을 평가하는 4가지 방식

##install.packages("MLmetrics")
library(MLmetrics)
MSE(y_pred = pred1, y_true = real)
RMSE(y_pred = pred1, y_true = real)
MAE(y_pred = pred1, y_true = real)
MAPE(y_pred = pred1, y_true = real)  #아직은 의미가 없음...;ㅅ; , 입력변수가 1개인 경우

> MSE(y_pred = pred1, y_true = real)
[1] 2325009
> RMSE(y_pred = pred1, y_true = real)
[1] 1524.798
> MAE(y_pred = pred1, y_true = real)
[1] 1138.776
> MAPE(y_pred = pred1, y_true = real)
[1] 0.1192655

full<- lm(formula = Price ~., data=trainSet)
null<- lm(formula = Price ~1, data=trainSet)
fit3 <- step(object = null,
             scope=list(lower=null, upper=full),
             direction = 'both') # forward 전진 backward 후진소거법 both면 단계적방법
             
Start:  AIC=15414.17
Price ~ 1

            Df  Sum of Sq        RSS   AIC
+ Age        1 6990054979 2017000997 13980
+ KM         1 3124469915 5882586061 15007
+ Weight     1 1889611945 7117444032 15190
+ Doors      1  390038344 8617017632 15374
+ HP         1  388270242 8618785734 15374
+ FuelType   1  129404922 8877651054 15402
+ MetColor   1  125176701 8881879275 15403
<none>                    9007055976 15414
+ Automatic  1    3491699 9003564277 15416

Step:  AIC=13979.63
Price ~ Age

            Df  Sum of Sq        RSS   AIC
+ KM         1  251322910 1765678087 13854
+ HP         1  152378906 1864622091 13906
+ Weight     1  127172205 1889828792 13919
+ FuelType   1  107654799 1909346198 13929
+ Doors      1   52793947 1964207050 13956
+ Automatic  1   38269893 1978731104 13963
+ MetColor   1    7814501 2009186496 13978
<none>                    2017000997 13980
- Age        1 6990054979 9007055976 15414

Step:  AIC=13853.87
Price ~ Age + KM

            Df  Sum of Sq        RSS   AIC
+ Weight     1  310045230 1455632856 13670
+ Doors      1   60399818 1705278269 13822
+ HP         1   56637177 1709040910 13825
+ Automatic  1   19553316 1746124771 13845
+ MetColor   1    6973579 1758704508 13852
<none>                    1765678087 13854
+ FuelType   1    3312976 1762365110 13854
- KM         1  251322910 2017000997 13980
- Age        1 4116907975 5882586061 15007

Step:  AIC=13670.5
Price ~ Age + KM + Weight

            Df  Sum of Sq        RSS   AIC
+ FuelType   1  154296586 1301336271 13565
+ HP         1   38054556 1417578300 13647
<none>                    1455632856 13670
+ MetColor   1    1661839 1453971018 13671
+ Automatic  1    1373971 1454258886 13672
+ Doors      1     379269 1455253587 13672
- Weight     1  310045230 1765678087 13854
- KM         1  434195935 1889828792 13919
- Age        1 2195301081 3650933938 14551

Step:  AIC=13564.94
Price ~ Age + KM + Weight + FuelType

            Df  Sum of Sq        RSS   AIC
+ HP         1   19159887 1282176384 13553
+ Doors      1   11269595 1290066676 13559
<none>                    1301336271 13565
+ Automatic  1     181577 1301154693 13567
+ MetColor   1     119887 1301216384 13567
- FuelType   1  154296586 1455632856 13670
- KM         1  154403139 1455739410 13671
- Weight     1  461028840 1762365110 13854
- Age        1 2236428778 3537765048 14523

Step:  AIC=13552.7
Price ~ Age + KM + Weight + FuelType + HP

            Df  Sum of Sq        RSS   AIC
+ Doors      1   16451012 1265725372 13542
<none>                    1282176384 13553
+ Automatic  1    2069952 1280106432 13553
+ MetColor   1     256028 1281920356 13554
- HP         1   19159887 1301336271 13565
- FuelType   1  135401916 1417578300 13647
- KM         1  148394104 1430570488 13656
- Weight     1  416080423 1698256807 13820
- Age        1 2137958644 3420135028 14493

Step:  AIC=13542.3
Price ~ Age + KM + Weight + FuelType + HP + Doors

            Df  Sum of Sq        RSS   AIC
+ Automatic  1    5258964 1260466408 13540
<none>                    1265725372 13542
+ MetColor   1     629312 1265096060 13544
- Doors      1   16451012 1282176384 13553
- HP         1   24341304 1290066676 13559
- KM         1  142829454 1408554826 13643
- FuelType   1  151819241 1417544613 13649
- Weight     1  390112006 1655837377 13798
- Age        1 2082465811 3348191183 14474

Step:  AIC=13540.3
Price ~ Age + KM + Weight + FuelType + HP + Doors + Automatic

            Df  Sum of Sq        RSS   AIC
<none>                    1260466408 13540
+ MetColor   1     570081 1259896327 13542
- Automatic  1    5258964 1265725372 13542
- Doors      1   19640024 1280106432 13553
- HP         1   28656162 1289122570 13560
- KM         1  146068126 1406534534 13644
- FuelType   1  154810674 1415277082 13650
- Weight     1  370560877 1631027285 13786
- Age        1 1923637868 3184104276 14428

---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 1151 on 952 degrees of freedom
Multiple R-squared:  0.8601,	Adjusted R-squared:  0.859 
F-statistic: 835.8 on 7 and 952 DF,  p-value: < 2.2e-16


summary(fit3) # 귀무가설(이 회귀식에 사용된 모든 입력변수의 회귀계수 = 0) 기각, 따라서 최소 1개는 0이 아니다
Call:
lm(formula = Price ~ Age + KM + Weight + FuelType + HP + Doors + 
    Automatic, data = trainSet)

Residuals:
    Min      1Q  Median      3Q     Max 
-5266.4  -759.0   -34.6   646.9  6124.9 

Coefficients:
                 Estimate Std. Error t value Pr(>|t|)    
(Intercept)    -1.947e+04  2.173e+03  -8.959  < 2e-16 ***
Age            -1.136e+02  2.980e+00 -38.117  < 2e-16 ***
KM             -1.513e-02  1.440e-03 -10.503  < 2e-16 ***
Weight          3.508e+01  2.097e+00  16.729  < 2e-16 ***
FuelTypePetrol  3.369e+03  3.116e+02  10.813  < 2e-16 ***
HP             -2.258e+01  4.853e+00  -4.652 3.75e-06 ***
Doors          -1.812e+02  4.705e+01  -3.851 0.000125 ***
Automatic1     -3.363e+02  1.688e+02  -1.993 0.046549 *  
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 1151 on 952 degrees of freedom
Multiple R-squared:  0.8601,	Adjusted R-squared:  0.859 
F-statistic: 835.8 on 7 and 952 DF,  p-value: < 2.2e-16

> #모든 회귀계수는 0이 아니라고 판단,  그다음 adjusted r-squared 를 확인 입력변수들이 목표변수를 얼마나 설명하는지..(0.859)
> 
> # 조정된 결정계수
> vif(mod=fit3)
      Age        KM    Weight  FuelType        HP     Doors Automatic 
 1.944137  1.974635  3.866463  5.192541  2.709247  1.446735  1.172139 
> # 분산팽창지수가 10을 초과하는 입력변수가 없으므로, 이 예제에는 다중공선성 문젤르 일으키는 입력변수는 없는 것으로 판단한다.
> # 만약 분산팽창지수가 10을 초과하는 입력변수가 여러개 있을 경우, 분산팽창지수가 자아 큰 입력변수 하나만 훈련셋에서 삭제하고 회귀모형을 다시 적합한다.
> # 새로 적합한 회귀모형의 분산팽창지수를 확인하고 분산팽창지수가 10을 초과하는 변수가 없을 때까지 위 과정 반복한다.

#표준화 회귀계수 :방향이 아니라 절대값이 중요하다.
# 숫자가 가장 큰게 Price에 제일 영향을 많이 줄까? 척도가 다 다르기 때문에 1:1로 입력변수들을 비교할 수 없다.
# 어떤 입력변수가 목표변수에 영향을 주는지 알기 위해서 표준화 회귀계수를 실행

###install.packages("reghelper")
library(reghelper)
beta(model=fit3)

> beta(model=fit3)

Call:
lm(formula = "Price.z ~ Age.z + KM.z + Weight.z + FuelTypePetrol.z + HP.z + Doors.z + Automatic1.z", 
    data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-1.71844 -0.24766 -0.01128  0.21109  1.99856 

Coefficients:
                   Estimate Std. Error t value Pr(>|t|)    
(Intercept)       6.886e-18  1.212e-02   0.000 1.000000    
Age.z            -6.444e-01  1.691e-02 -38.117  < 2e-16 ***
KM.z             -1.789e-01  1.704e-02 -10.503  < 2e-16 ***
Weight.z          3.988e-01  2.384e-02  16.729  < 2e-16 ***
FuelTypePetrol.z  2.987e-01  2.763e-02  10.813  < 2e-16 ***
HP.z             -9.284e-02  1.996e-02  -4.652 3.75e-06 ***
Doors.z          -5.617e-02  1.458e-02  -3.851 0.000125 ***
Automatic1.z     -2.616e-02  1.313e-02  -1.993 0.046549 *  
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.3755 on 952 degrees of freedom
Multiple R-squared:  0.8601,	Adjusted R-squared:  0.859 
F-statistic: 835.8 on 7 and 952 DF,  p-value: < 2.2e-16

> beta.z<-beta(model=fit3) 
> beta.z$coefficients[,1] # 행렬이므로 첫번째 컬럼만 가져와야 한다. 벡터로 표준화 회귀계수를 가져온다.
     (Intercept)            Age.z             KM.z         Weight.z FuelTypePetrol.z             HP.z          Doors.z     Automatic1.z 
    6.885978e-18    -6.443675e-01    -1.789492e-01     3.988369e-01     2.987439e-01    -9.284145e-02    -5.616607e-02    -2.616063e-02 
> round(x=beta.z$coefficients[,1], digits = 4)  # 한눈에 알아보기 어려우므로 반올림 처리
     (Intercept)            Age.z             KM.z         Weight.z FuelTypePetrol.z             HP.z          Doors.z     Automatic1.z 
          0.0000          -0.6444          -0.1789           0.3988           0.2987          -0.0928          -0.0562          -0.0262 
# 표준화 회귀계수는 방향이 아니라 절대값이 중요하다. 연식> 무게> 연료형태>주행거리
# 분석보고서 제출시에 표준화 회귀계수를 구하여 어떤 요소가 영향을 주는지 설명해야한다.

pred2 <- predict(object= fit3, newdata=testSet)
print(x=pred2)  #named vector라고 한다 412행의 값이 7508.588

# 성능평가

RMSE(y_pred = pred1, y_true = real)
RMSE(y_pred = pred2, y_true = real) # 이 중 0에 더 가까운 것은 pred2이다.

##Price에 더 높은 성능을 보이는 유형은 fit3이다 입력변수가 여러개 쓰인 것이다. fit3를 최종모형으로 선택
